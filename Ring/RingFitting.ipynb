{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "22sDvsSe4Ed-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a959818c-e8eb-48e1-eb0f-e4b542d69b76"
      },
      "source": [
        "! pip install -U opencv-python pillow pyyaml tqdm\r\n",
        "import torch\r\n",
        "from PIL import Image\r\n",
        "model = torch.hub.load('ultralytics/yolov5', 'custom', path_or_model='best_bw_400.pt') \r\n",
        "import cv2\r\n",
        "img = cv2.imread('t1.jpeg')#Imagename here\r\n",
        "img = cv2.resize(img, (960, 1240))\r\n",
        "img2 = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\r\n",
        "results = model(img2)\r\n",
        "a=results.xyxy[0]\r\n",
        "for i in range(0,len(a)):\r\n",
        "  if(a[i][5]==1):\r\n",
        "    middle=a[i][0:5]\r\n",
        "  if(a[i][5]==2):\r\n",
        "    ring=a[i][0:4]\r\n",
        "mbottom = middle[0:2]\r\n",
        "mtop = middle[2:4]\r\n",
        "rbottom = ring[0:2]\r\n",
        "rtop = ring[2:4]\r\n",
        "color = (0,0,0)\r\n",
        "thickness = 2\r\n",
        "ring_width = int(abs(rtop[0]-rbottom[0]))\r\n",
        "ring_length = int(ring_width//2)\r\n",
        "img_ring = cv2.imread('ring4.png',-1)\r\n",
        "img_ring = cv2.resize(img_ring,(ring_width,ring_length))\r\n",
        "x_off = int(rbottom[0]+0.9)\r\n",
        "y_off = int(rbottom[1]+ring_length//1.5)\r\n",
        "gw,gh,gc = img_ring.shape\r\n",
        "print(img_ring.shape)\r\n",
        "for i in range(0, gw):\r\n",
        "    for j in range(0, gh): \r\n",
        "        if img_ring[i, j][3] != 0:\r\n",
        "            img[ y_off + i,x_off+j] = img_ring[i,j][0:3]\r\n",
        "cv2.imwrite(\"Plot.jpeg\",img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: opencv-python in /usr/local/lib/python3.7/dist-packages (4.5.1.48)\n",
            "Requirement already up-to-date: pillow in /usr/local/lib/python3.7/dist-packages (8.1.2)\n",
            "Requirement already up-to-date: pyyaml in /usr/local/lib/python3.7/dist-packages (5.4.1)\n",
            "Requirement already up-to-date: tqdm in /usr/local/lib/python3.7/dist-packages (4.59.0)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
            "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model Summary: 283 layers, 7260488 parameters, 7260488 gradients\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Adding autoShape... \n",
            "tensor([[4.10458e+02, 8.73032e+02, 5.07897e+02, 1.23048e+03, 8.23315e-01, 1.00000e+00],\n",
            "        [5.35813e+02, 8.51799e+02, 6.28572e+02, 1.19116e+03, 7.54825e-01, 2.00000e+00],\n",
            "        [2.85984e+02, 8.70807e+02, 3.80260e+02, 1.17929e+03, 6.92990e-01, 0.00000e+00]])\n",
            "tensor([4.10458e+02, 8.73032e+02, 5.07897e+02, 1.23048e+03, 8.23315e-01]) tensor([ 535.81335,  851.79901,  628.57202, 1191.15686])\n",
            "(46, 92, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaItea65RXpD"
      },
      "source": [
        ""
      ]
    }
  ]
}