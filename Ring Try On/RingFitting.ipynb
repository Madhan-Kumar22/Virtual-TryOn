{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22sDvsSe4Ed-",
    "outputId": "7ff51cde-178a-4220-9256-d2ac349f63af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: opencv-python in /usr/local/lib/python3.7/dist-packages (4.5.1.48)\n",
      "Requirement already up-to-date: pillow in /usr/local/lib/python3.7/dist-packages (8.1.2)\n",
      "Requirement already up-to-date: pyyaml in /usr/local/lib/python3.7/dist-packages (5.4.1)\n",
      "Requirement already up-to-date: tqdm in /usr/local/lib/python3.7/dist-packages (4.59.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python) (1.19.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /root/.cache/torch/hub/ultralytics_yolov5_master\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      3520  models.common.Focus                     [3, 32, 3]                    \n",
      "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
      "  2                -1  1     19904  models.common.BottleneckCSP             [64, 64, 1]                   \n",
      "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  4                -1  1    161152  models.common.BottleneckCSP             [128, 128, 3]                 \n",
      "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  6                -1  1    641792  models.common.BottleneckCSP             [256, 256, 3]                 \n",
      "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  8                -1  1    656896  models.common.SPP                       [512, 512, [5, 9, 13]]        \n",
      "  9                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
      " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
      " 13                -1  1    378624  models.common.BottleneckCSP             [512, 256, 1, False]          \n",
      " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
      " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
      " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
      " 17                -1  1     95104  models.common.BottleneckCSP             [256, 128, 1, False]          \n",
      " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
      " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
      " 20                -1  1    313088  models.common.BottleneckCSP             [256, 256, 1, False]          \n",
      " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
      " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
      " 23                -1  1   1248768  models.common.BottleneckCSP             [512, 512, 1, False]          \n",
      " 24      [17, 20, 23]  1     21576  models.yolo.Detect                      [3, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
      "Model Summary: 283 layers, 7260488 parameters, 7260488 gradients\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding autoShape... \n",
      "(28, 56, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Installing Libraries\n",
    "! pip install -U opencv-python pillow pyyaml tqdm\n",
    "#Importing Required Libraries\n",
    "import torch\n",
    "from PIL import Image\n",
    "#Loading Custom model weights file to the model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path_or_model='best_bw_400.pt') \n",
    "#Import OpenCV to work with images\n",
    "import cv2\n",
    "#Reading Image\n",
    "img = cv2.imread('Test4.jpeg')\n",
    "img = cv2.resize(img, (960, 1240))\n",
    "#Converting Image to GRAYSCALE \n",
    "img2 = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "#Putting the image through finger detection model\n",
    "results = model(img2)\n",
    "a=results.xyxy[0]\n",
    "#Getting Coordinates of Middle finger and Ring Finger\n",
    "for i in range(0,len(a)):\n",
    "  if(a[i][5]==1):\n",
    "    middle=a[i][0:5]\n",
    "  if(a[i][5]==2):\n",
    "    ring=a[i][0:4]\n",
    "#The top and bottom corner coordinates of each finger\n",
    "mbottom = middle[0:2]\n",
    "mtop = middle[2:4]\n",
    "rbottom = ring[0:2]\n",
    "rtop = ring[2:4]\n",
    "color = (0,0,0)\n",
    "thickness = 2\n",
    "#Taking the width of the finger and resizing the ring image to these lengths\n",
    "ring_width = int(abs(rtop[0]-rbottom[0]))\n",
    "ring_length = int(ring_width//2)\n",
    "#Reading the Ring Image\n",
    "img_ring = cv2.imread('ring.png',-1)\n",
    "img_ring = cv2.resize(img_ring,(ring_width,ring_length))\n",
    "\n",
    "x_off = int(rbottom[0]+0.9)\n",
    "y_off = int(rbottom[1]+ring_length//1.5)\n",
    "gw,gh,gc = img_ring.shape\n",
    "print(img_ring.shape)\n",
    "#Super imposing watch on the hand \n",
    "for i in range(0, gw):\n",
    "    for j in range(0, gh): \n",
    "        if img_ring[i, j][3] != 0:\n",
    "            img[ y_off + i,x_off+j] = img_ring[i,j][0:3]\n",
    "#Rotate Image by 190 degrees\n",
    "img = cv2.rotate(img, cv2.ROTATE_180) \n",
    "#Saving the Image\n",
    "cv2.imwrite(\"Result.jpeg\",img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaItea65RXpD"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RingFitting.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
